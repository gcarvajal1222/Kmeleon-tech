{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\gabri\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\gabri\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\gabri\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\gabri\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize \n",
    "import warnings \n",
    "import nltk\n",
    "#from gensim.models import Word2Vec \n",
    "#from gensim.models.wrappers import FastText \n",
    "\n",
    "#from gensim.models import FastText\n",
    "\n",
    "\n",
    "\n",
    "from IPython.display import clear_output, display\n",
    "\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize \n",
    "import warnings \n",
    "import nltk \n",
    "import pandas as pd\n",
    "from pandas import *\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.stem import WordNetLemmatizer,PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "stemmer = PorterStemmer() \n",
    "import re\n",
    "from sklearn.feature_extraction import text\n",
    "from builtins import input\n",
    "from statistics import mean\n",
    "from nltk import  pos_tag_sents\n",
    "\n",
    "\n",
    "from statistics import mode, StatisticsError\n",
    "\n",
    "import functools\n",
    "\n",
    "\n",
    "import re\n",
    "from sklearn.feature_extraction import text\n",
    "global cases\n",
    "\n",
    "from pandas import ExcelWriter\n",
    "import xlsxwriter\n",
    "\n",
    "import xlwt\n",
    "from xlwt.Workbook import *\n",
    "\n",
    "\n",
    "from nltk.corpus import wordnet\n",
    "\n",
    "from statistics import *\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "from nltk import pos_tag\n",
    "from nltk.tokenize.treebank import TreebankWordDetokenizer\n",
    "import seaborn as sns\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('vader_lexicon')\n",
    "import nltk\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = pd.read_excel(\"faq-extract-text.xlsx\", sheet_name =\"only text\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ds=pd.Series(df['faq text'].str.lower().unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def similar(a, b):\n",
    "    return difflib.SequenceMatcher(None, a, b).ratio()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using different distances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Differences distances\n",
    "\n",
    "Functions\n",
    "\n",
    "hamming\n",
    "\n",
    "mlipns\n",
    "\n",
    "levenshtein\n",
    "\n",
    "damerau_levenshtein\n",
    "\n",
    "jaro_winkler, jaro\n",
    "\n",
    "strcmp95\n",
    "\n",
    "needleman_wunsch\n",
    "\n",
    "gotoh\n",
    "\n",
    "smith_waterman"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def similarityTexts (string1, string2, focus):\n",
    "    \n",
    "    print(string1,\"vs\", string2 , \":\", focus)\n",
    "\n",
    "    print(\"\\n\")\n",
    "\n",
    "    print(\"jaro winkler:\",textdistance.jaro_winkler.normalized_similarity(string1, string2)) \n",
    "\n",
    "    print (\"sequence matcher:\" , difflib.SequenceMatcher(None, string1, string2).ratio())\n",
    "\n",
    "    print(\"hamming distance:\", textdistance.hamming.normalized_similarity(string1, string2))\n",
    "\n",
    "    print(\"smith_waterman:\", textdistance.smith_waterman.normalized_similarity(string1, string2))\n",
    "\n",
    "    print(\"levenshtein:\", textdistance.levenshtein.normalized_similarity(string1, string2))\n",
    "    \n",
    "    print(\"needleman_wunsch:\", textdistance.needleman_wunsch.normalized_similarity(string1, string2) )\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Focusing on Extra characters\n",
    "\n",
    "\"where's the pool\" vs \"where is the pool\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "where's the pool vs where is the pool : Focusing on extra characters\n",
      "\n",
      "\n",
      "jaro winkler: 0.9239705882352942\n",
      "sequence matcher: 0.9090909090909091\n",
      "hamming distance: 0.3529411764705882\n",
      "smith_waterman: 0.875\n",
      "levenshtein: 0.8823529411764706\n",
      "needleman_wunsch: 0.9117647058823529\n"
     ]
    }
   ],
   "source": [
    "similarityTexts(\"where's the pool\", \"where is the pool\", \"Focusing on extra characters\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Focusing on different intents \n",
    "\n",
    "These examples focuses on unanswered questions at the beggining of a question where it could be different\n",
    "\n",
    "We want these scores to be lower\n",
    "\n",
    "Luis should be able to predict that the intent for both questions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "what is the pool schedule vs where is the pool : Focusing on asking totally different questions but are similar\n",
      "\n",
      "\n",
      "jaro winkler: 0.7908496732026145\n",
      "sequence matcher: 0.6666666666666666\n",
      "hamming distance: 0.12\n",
      "smith_waterman: 0.23529411764705888\n",
      "levenshtein: 0.52\n",
      "needleman_wunsch: 0.58\n"
     ]
    }
   ],
   "source": [
    "similarityTexts (\"what is the pool schedule\", \"where is the pool\", \"Focusing on asking totally different questions but are similar\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Focusing on the different locations in a string\n",
    "\n",
    "This person probably doesn't know english \n",
    "\n",
    "\"where is the pool vs the pool where is:\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "where is the pool vs the pool where is : Focusing on the different locations in a string\n",
      "\n",
      "\n",
      "jaro winkler: 0.6053921568627451\n",
      "sequence matcher: 0.47058823529411764\n",
      "hamming distance: 0.2941176470588235\n",
      "smith_waterman: 0.2941176470588235\n",
      "levenshtein: 0.2941176470588235\n",
      "needleman_wunsch: 0.6470588235294118\n"
     ]
    }
   ],
   "source": [
    "similarityTexts (\"where is the pool\", \"the pool where is\", \"Focusing on the different locations in a string\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fosuing on longer substring\n",
    "\n",
    "if a string is part of a substring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "where is the pool in the hotel vs where is the pool : longer substring\n",
      "\n",
      "\n",
      "jaro winkler: 0.9133333333333333\n",
      "sequence matcher: 0.723404255319149\n",
      "hamming distance: 0.5666666666666667\n",
      "smith_waterman: 0.47058823529411764\n",
      "levenshtein: 0.5666666666666667\n",
      "needleman_wunsch: 0.5666666666666667\n"
     ]
    }
   ],
   "source": [
    "similarityTexts (\"where is the pool in the hotel\", \"where is the pool\", \"longer substring\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Focusing on different entitities\n",
    "\n",
    "how much does the pool cost vs how much is the buffet?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "how much does the pool cost vs how much does the buffet cost : different entities\n",
      "\n",
      "\n",
      "jaro winkler: 0.9202954078516298\n",
      "sequence matcher: 0.8214285714285714\n",
      "hamming distance: 0.6206896551724138\n",
      "smith_waterman: 0.7777777777777778\n",
      "levenshtein: 0.7931034482758621\n",
      "needleman_wunsch: 0.8620689655172413\n"
     ]
    }
   ],
   "source": [
    "similarityTexts (\"how much does the pool cost\", \"how much does the buffet cost\", \"different entities\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict Intent and Entity without luis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import en_core_web_sm\n",
    "nlp = en_core_web_sm.load()\n",
    "\n",
    "sample = pd.Series(\"Where is the store?\").apply(nlp)\n",
    "\n",
    "sample2 = nlp(\"Where is the store?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ENTITY: ['store']\n"
     ]
    }
   ],
   "source": [
    "#for token in sample[token]: \n",
    "#    print(token, token.pos_) \n",
    "  \n",
    "# You want list of Verb tokens \n",
    "print(\"ENTITY:\", [token.text for token in sample2 if token.pos_ == \"NOUN\"]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method Synset.definition of Synset('hershey.n.01')>\n",
      "<bound method Synset.lemma_names of Synset('hershey.n.01')>\n",
      "<bound method Synset.definition of Synset('hershey.n.02')>\n",
      "<bound method Synset.lemma_names of Synset('hershey.n.02')>\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import wordnet as wn\n",
    "for ss in wn.synsets(''): # Each synset represents a diff concept.\n",
    "    print(ss.definition)\n",
    "    print (ss.lemma_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extra code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  #Fuzzy matching for similar words that IRI knows (in the brand name) and getting rid off them\n",
    "\n",
    "# import difflib\n",
    "    \n",
    "# def similar(a, b):\n",
    "#     return difflib.SequenceMatcher(None, a, b).ratio()\n",
    "\n",
    "    \n",
    "\n",
    "# x1_none = (ds.str.strip())\n",
    "#  #words that contain tag\n",
    "# y1_words_in_brand = pd.Series(\"where is the pool located\") #words in v4_brand field \n",
    "# threshold = 0.80  #Can test with different ratios for different categories \n",
    "\n",
    "    \n",
    "\n",
    "# result_fuzzy_words_df_none = [x for x in x1_none for y in y1_words_in_brand if similar(x, y) > threshold]\n",
    "\n",
    "# print(\"counts of fuzzywords in df_none :\", len(result_fuzzy_words_df_none)) \n",
    "\n",
    "    \n",
    "\n",
    "    \n",
    "\n",
    "# #getting rid off fuzzy matches that are in high ratios\n",
    "\n",
    "#     # Example: nestl and nestle, hersheys and hersheeys for chocolate_candy category \n",
    "\n",
    "    \n",
    "\n",
    "# #Converting list to pd.series to only get the unique fuzzy words\n",
    "\n",
    "# result_fuzzy_words_df_none_S= pd.Series(result_fuzzy_words_df_none).unique()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
